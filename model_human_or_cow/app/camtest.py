import argparse
import os
import cv2
import time
import sys
from datetime import datetime
from pathlib import Path
from loguru import logger
from typing import Optional

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–¥ –∞–≤—Ç–æ—Ä–∞
try:
    from predict import Predictor, DetectedObject
    PREDICTOR_AVAILABLE = True
    logger.info("‚úÖ Predictor –º–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    PREDICTOR_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Predictor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    logger.warning("–†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –∫–∞–º–µ—Ä—ã")


class IntegratedCamera:
    def __init__(self, args):
        self.args = args
        self.cap = None
        self.predictor = None
        self.frame_count = 0
        self.start_time = time.time()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.init_camera()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ –∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        if PREDICTOR_AVAILABLE and args.mode in ['track', 'both']:
            self.init_ai_predictor()
        elif args.mode in ['track', 'both'] and not PREDICTOR_AVAILABLE:
            logger.error("‚ùå AI —Ä–µ–∂–∏–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - Predictor –Ω–µ –Ω–∞–π–¥–µ–Ω")
            logger.info("–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –∫–∞–º–µ—Ä—ã...")
            self.args.mode = 'simple'
    
    def init_camera(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã"""
        logger.info(f"üé• –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã —Å ID: {self.args.camera_id}")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–∞–º–µ—Ä—ã
        for camera_id in [self.args.camera_id, 0, 1, 2]:
            self.cap = cv2.VideoCapture(camera_id)
            if self.cap.isOpened():
                ret, frame = self.cap.read()
                if ret:
                    logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞ {camera_id} —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    self.args.camera_id = camera_id
                    break
                else:
                    self.cap.release()
            else:
                if self.cap:
                    self.cap.release()
        else:
            raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—á—É—é –∫–∞–º–µ—Ä—É")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
        if self.args.width and self.args.height:
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.args.width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.args.height)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS)) or 30
        
        logger.info(f"‚úÖ –ö–∞–º–µ—Ä–∞: {self.width}x{self.height} @ {self.fps}fps")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ
        if self.args.save_video:
            self.init_video_writer()
    
    def init_video_writer(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        mode_name = {
            'simple': 'simple_camera',
            'track': 'ai_tracking', 
            'both': 'combined'
        }.get(self.args.mode, 'camera')
        
        filename = f"{mode_name}_{timestamp}.mp4"
        self.output_path = Path(self.args.output_dir) / filename
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        self.video_writer = cv2.VideoWriter(
            str(self.output_path), fourcc, self.fps, (self.width, self.height)
        )
        logger.info(f"üìπ –í–∏–¥–µ–æ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {self.output_path}")
    
    def init_ai_predictor(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞"""
        try:
            logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞...")
            
            weights_path = Path(self.args.weights)
            if not weights_path.exists():
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≤–µ—Å–∞
                possible_weights = [
                    "artifacts/train-seg/weights/best.pt",
                    "best.pt",
                    "yolov8n-seg.pt"
                ]
                
                for weight_file in possible_weights:
                    if Path(weight_file).exists():
                        weights_path = Path(weight_file)
                        logger.info(f"üîç –ù–∞–π–¥–µ–Ω—ã –≤–µ—Å–∞: {weights_path}")
                        break
                else:
                    logger.warning("‚ö†Ô∏è –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    logger.info("üí° –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å YOLOv8n-seg...")
                    weights_path = "yolov8n-seg.pt"  # Ultralytics –∑–∞–≥—Ä—É–∑–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
            self.predictor = Predictor(
                weights=weights_path,
                device=self.args.device
            )
            
            logger.info("‚úÖ AI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI: {e}")
            import traceback
            traceback.print_exc()
            self.predictor = None
    
    def draw_detections(self, frame, detections):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π –Ω–∞ –∫–∞–¥—Ä–µ"""
        if not detections:
            return frame
        
        result_frame = frame.copy()
        
        for det in detections:
            # –†–∏—Å—É–µ–º –±ounding box
            if det.bbox_xyxy:
                x1, y1, x2, y2 = map(int, det.bbox_xyxy)
                
                # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–ª–∞—Å—Å–∞
                color = (0, 255, 0) if det.cls_name == 'cow' else (255, 0, 0)
                
                cv2.rectangle(result_frame, (x1, y1), (x2, y2), color, 2)
                
                # –ü–æ–¥–ø–∏—Å—å
                label = f"{det.cls_name}: {det.conf:.2f}"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                
                # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                cv2.rectangle(result_frame, 
                            (x1, y1 - label_size[1] - 10), 
                            (x1 + label_size[0], y1), 
                            color, -1)
                
                # –¢–µ–∫—Å—Ç
                cv2.putText(result_frame, label, 
                          (x1, y1 - 5), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # –†–∏—Å—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if det.seg_xy and len(det.seg_xy) >= 6:  # –ú–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏
                try:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array —Ç–æ—á–µ–∫
                    points = []
                    for i in range(0, len(det.seg_xy), 2):
                        if i + 1 < len(det.seg_xy):
                            points.append([int(det.seg_xy[i]), int(det.seg_xy[i + 1])])
                    
                    if len(points) >= 3:
                        import numpy as np
                        pts = np.array(points, np.int32)
                        pts = pts.reshape((-1, 1, 2))
                        
                        # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω–∞—è –∑–∞–ª–∏–≤–∫–∞
                        overlay = result_frame.copy()
                        color = (0, 255, 0) if det.cls_name == 'cow' else (255, 0, 0)
                        cv2.fillPoly(overlay, [pts], color)
                        result_frame = cv2.addWeighted(result_frame, 0.7, overlay, 0.3, 0)
                        
                        # –ö–æ–Ω—Ç—É—Ä
                        cv2.polylines(result_frame, [pts], True, color, 2)
                        
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        
        return result_frame
    
    def run_simple_camera(self):
        """–ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –∫–∞–º–µ—Ä—ã"""
        logger.info("üé• –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞ –∫–∞–º–µ—Ä—ã")
        logger.info("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: ESC/Q - –≤—ã—Ö–æ–¥, S - —Å–∫—Ä–∏–Ω—à–æ—Ç, R - –∑–∞–ø–∏—Å—å")
        
        recording = False
        screenshot_count = 0
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã")
                break
            
            self.frame_count += 1
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä
            current_fps = self.frame_count / (time.time() - self.start_time)
            info_text = f"FPS: {current_fps:.1f} | Frame: {self.frame_count}"
            
            if recording:
                info_text += " | ‚è∫ REC"
                cv2.circle(frame, (30, 30), 10, (0, 0, 255), -1)
            
            cv2.putText(frame, info_text, (10, self.height - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
            if recording and hasattr(self, 'video_writer'):
                self.video_writer.write(frame)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.imshow("Camera - Simple Mode", frame)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            if key in [27, ord('q'), ord('Q')]:
                break
            elif key in [ord('s'), ord('S')]:
                screenshot_count += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                screenshot_path = f"screenshot_{timestamp}_{screenshot_count:03d}.jpg"
                cv2.imwrite(screenshot_path, frame)
                logger.info(f"üì∑ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
            elif key in [ord('r'), ord('R')]:
                if not hasattr(self, 'video_writer'):
                    self.init_video_writer()
                recording = not recording
                logger.info(f"üìπ –ó–∞–ø–∏—Å—å {'–≤–∫–ª—é—á–µ–Ω–∞' if recording else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}")
    
    def run_ai_tracking(self):
        """–†–µ–∂–∏–º AI –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        if not self.predictor:
            logger.error("‚ùå AI –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º...")
            self.run_simple_camera()
            return
        
        logger.info("ü§ñ –ó–∞–ø—É—Å–∫ AI –¥–µ—Ç–µ–∫—Ü–∏–∏")
        logger.info("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: ESC/Q - –≤—ã—Ö–æ–¥, S - —Å–∫—Ä–∏–Ω—à–æ—Ç")
        
        screenshot_count = 0
        detection_results = []
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã")
                break
            
            self.frame_count += 1
            
            try:
                # AI –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–∞–¥—Ä –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                temp_path = "temp_frame.jpg"
                cv2.imwrite(temp_path, frame)
                
                predictions = self.predictor.predict(
                    source=temp_path,
                    conf=self.args.conf,
                    iou=self.args.iou,
                    save=False
                )
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ) –∫–∞–¥—Ä–∞
                detections = predictions[0] if predictions else []
                
                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π
                result_frame = self.draw_detections(frame, detections)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if detections:
                    frame_results = {
                        'frame': self.frame_count,
                        'timestamp': time.time(),
                        'detections': [
                            {
                                'class': det.cls_name,
                                'confidence': det.conf,
                                'bbox': det.bbox_xyxy
                            }
                            for det in detections
                        ]
                    }
                    detection_results.append(frame_results)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                result_frame = frame
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –∫–∞–¥—Ä
            current_fps = self.frame_count / (time.time() - self.start_time)
            total_detections = sum(len(r['detections']) for r in detection_results)
            
            info_text = f"FPS: {current_fps:.1f} | Frame: {self.frame_count} | Det: {total_detections}"
            cv2.putText(result_frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ
            if self.args.save_video and hasattr(self, 'video_writer'):
                self.video_writer.write(result_frame)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.imshow("Camera - AI Detection", result_frame)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            if key in [27, ord('q'), ord('Q')]:
                break
            elif key in [ord('s'), ord('S')]:
                screenshot_count += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                screenshot_path = f"ai_screenshot_{timestamp}_{screenshot_count:03d}.jpg"
                cv2.imwrite(screenshot_path, result_frame)
                logger.info(f"üì∑ AI —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            if self.frame_count % 30 == 0:
                current_detections = len(detections) if 'detections' in locals() else 0
                logger.info(f'Frame {self.frame_count} | FPS: {current_fps:.1f} | Current detections: {current_detections}')
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if detection_results and self.args.save_results:
            self.save_detection_results(detection_results)
    
    def run_combined_mode(self):
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞")
        logger.info("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: ESC/Q - –≤—ã—Ö–æ–¥, T - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ AI, S - —Å–∫—Ä–∏–Ω—à–æ—Ç")
        
        ai_enabled = self.predictor is not None
        ai_active = ai_enabled
        screenshot_count = 0
        
        if not ai_enabled:
            logger.warning("‚ö†Ô∏è AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º")
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã")
                break
            
            self.frame_count += 1
            original_frame = frame.copy()
            
            # AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
            if ai_active and self.predictor:
                try:
                    temp_path = "temp_frame.jpg"
                    cv2.imwrite(temp_path, frame)
                    
                    predictions = self.predictor.predict(
                        source=temp_path,
                        conf=self.args.conf,
                        iou=self.args.iou,
                        save=False
                    )
                    
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                    
                    detections = predictions[0] if predictions else []
                    frame = self.draw_detections(frame, detections)
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                    frame = original_frame
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –∫–∞–¥—Ä
            current_fps = self.frame_count / (time.time() - self.start_time)
            status = "AI ON" if ai_active else "AI OFF"
            info_text = f"FPS: {current_fps:.1f} | {status} | Frame: {self.frame_count}"
            
            cv2.putText(frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ä–µ–∂–∏–º–∞
            color = (0, 255, 0) if ai_active else (0, 0, 255)
            cv2.circle(frame, (self.width - 30, 30), 10, color, -1)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ
            if self.args.save_video and hasattr(self, 'video_writer'):
                self.video_writer.write(frame)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.imshow("Camera - Combined Mode", frame)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            if key in [27, ord('q'), ord('Q')]:
                break
            elif key in [ord('t'), ord('T')] and ai_enabled:
                ai_active = not ai_active
                logger.info(f"üîÑ AI –¥–µ—Ç–µ–∫—Ü–∏—è {'–≤–∫–ª—é—á–µ–Ω–∞' if ai_active else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}")
            elif key in [ord('s'), ord('S')]:
                screenshot_count += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                screenshot_path = f"combined_screenshot_{timestamp}_{screenshot_count:03d}.jpg"
                cv2.imwrite(screenshot_path, frame)
                logger.info(f"üì∑ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
    
    def save_detection_results(self, results):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_path = Path(self.args.output_dir) / f"detection_results_{timestamp}.txt"
        results_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_path, 'w') as f:
            f.write("frame,class,confidence,x1,y1,x2,y2\n")
            for frame_result in results:
                frame_num = frame_result['frame']
                for det in frame_result['detections']:
                    if det['bbox']:
                        x1, y1, x2, y2 = det['bbox']
                        f.write(f"{frame_num},{det['class']},{det['confidence']:.3f},"
                               f"{x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f}\n")
        
        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        try:
            if self.args.mode == 'simple':
                self.run_simple_camera()
            elif self.args.mode == 'track':
                self.run_ai_tracking()
            elif self.args.mode == 'both':
                self.run_combined_mode()
            else:
                logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {self.args.mode}")
        
        except KeyboardInterrupt:
            logger.info("üëã –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.cleanup()
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.cap:
            self.cap.release()
        if hasattr(self, 'video_writer'):
            self.video_writer.release()
        cv2.destroyAllWindows()
        logger.info("üßπ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")


def make_parser():
    parser = argparse.ArgumentParser(
        "Integrated Camera Application with AI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python integrated_camera_fixed.py simple                    # –ü—Ä–æ—Å—Ç–∞—è –∫–∞–º–µ—Ä–∞
  python integrated_camera_fixed.py track                     # AI –¥–µ—Ç–µ–∫—Ü–∏—è
  python integrated_camera_fixed.py both                      # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º
  python integrated_camera_fixed.py simple --save_video       # –° —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–∏–¥–µ–æ
        """
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("mode", choices=["simple", "track", "both"], 
                       help="–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã
    parser.add_argument("--camera_id", type=int, default=0, help="ID –∫–∞–º–µ—Ä—ã")
    parser.add_argument("--width", type=int, default=None, help="–®–∏—Ä–∏–Ω–∞ –∫–∞–¥—Ä–∞")
    parser.add_argument("--height", type=int, default=None, help="–í—ã—Å–æ—Ç–∞ –∫–∞–¥—Ä–∞")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    parser.add_argument("--save_video", action="store_true", help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤–∏–¥–µ–æ")
    parser.add_argument("--save_results", action="store_true", help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    parser.add_argument("--output_dir", type=str, default="./output", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    
    # AI –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å –∫–æ–¥–æ–º –∞–≤—Ç–æ—Ä–∞)
    parser.add_argument("--weights", type=str, default="artifacts/train-seg/weights/best.pt", 
                       help="–ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏")
    parser.add_argument("--device", type=str, default="cpu", help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu –∏–ª–∏ cuda")
    parser.add_argument("--conf", type=float, default=0.25, help="–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
    parser.add_argument("--iou", type=float, default=0.7, help="–ü–æ—Ä–æ–≥ IoU –¥–ª—è NMS")
    
    return parser


if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger.remove()
    logger.add(
        lambda msg: print(msg, end=""), 
        format="<green>{time:HH:mm:ss}</green> | <level>{level}</level> | {message}"
    )
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if len(sys.argv) == 1:
        parser = make_parser()
        parser.print_help()
        print("\nüöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:")
        print("python integrated_camera_fixed.py simple      # –ü—Ä–æ—Å—Ç–∞—è –∫–∞–º–µ—Ä–∞")
        print("python integrated_camera_fixed.py track       # AI –¥–µ—Ç–µ–∫—Ü–∏—è") 
        print("python integrated_camera_fixed.py both        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π")
        sys.exit(0)
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    parser = make_parser()
    args = parser.parse_args()
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã")
    logger.info(f"üìã –†–µ–∂–∏–º: {args.mode}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    app = IntegratedCamera(args)
    app.run()