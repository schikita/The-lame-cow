import cv2
import time
import argparse
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from predict import Predictor
except ImportError:
    print("‚ö†Ô∏è –ú–æ–¥—É–ª—å predict.py –Ω–µ –Ω–∞–π–¥–µ–Ω. AI —Ä–µ–∂–∏–º—ã –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
    Predictor = None

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è Ultralytics –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. Human detection –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
    YOLO_AVAILABLE = False


class HumanDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –ª—é–¥–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ YOLO"""
    
    def __init__(self, model_path='yolov8n.pt', conf_threshold=0.25):
        self.model = None
        self.conf_threshold = conf_threshold
        
        if YOLO_AVAILABLE:
            try:
                print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏: {model_path}")
                self.model = YOLO(model_path)
                print("‚úÖ YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO: {e}")
                self.model = None
        else:
            print("‚ùå YOLO –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    def detect(self, frame):
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∫–∞–¥—Ä–µ"""
        if not self.model:
            return []
        
        try:
            results = self.model(frame, conf=self.conf_threshold, verbose=False)
            detections = []
            
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        conf = float(box.conf[0])
                        
                        # –ö–ª–∞—Å—Å
                        class_id = int(box.cls[0])
                        class_name = self.model.names[class_id]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–±—ä–µ–∫—Ç —á–µ–ª–æ–≤–µ–∫–æ–º
                        is_human = class_name.lower() == 'person'
                        
                        detection = {
                            'bbox': [x1, y1, x2, y2],
                            'conf': conf,
                            'class_id': class_id,
                            'class_name': class_name,
                            'is_human': is_human
                        }
                        detections.append(detection)
            
            return detections
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return []


class CameraHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–∞–º–µ—Ä—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
    
    def __init__(self, mode="human", camera_id=0, weights_path=None, target_fps=30):
        self.mode = mode
        self.camera_id = camera_id
        self.target_fps = target_fps
        self.frame_count = 0
        self.start_time = time.time()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.cap = cv2.VideoCapture(camera_id)
        if not self.cap.isOpened():
            raise ValueError(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É {camera_id}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"üìπ –ö–∞–º–µ—Ä–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.width}x{self.height}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤
        self.human_detector = None
        self.predictor = None
        self.enable_human_detection = True
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if mode in ["human", "both", "both_with_human"]:
            self.human_detector = HumanDetector()
        
        if mode in ["track", "both", "both_with_human"]:
            if Predictor:
                try:
                    weights = weights_path or "artifacts/train-seg/weights/best.pt"
                    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ AI –º–æ–¥–µ–ª–∏: {weights}")
                    self.predictor = Predictor(weights)
                    print("‚úÖ AI –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ AI –º–æ–¥–µ–ª–∏: {e}")
                    self.predictor = None
            else:
                print("‚ùå AI –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    def draw_info_panel(self, frame, humans=0, non_humans=0, ai_detections=0):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –ø–∞–Ω–µ–ª–∏"""
        try:
            current_fps = self.frame_count / (time.time() - self.start_time) if (time.time() - self.start_time) > 0 else 0
            
            # –†–∞–∑–º–µ—Ä—ã –ø–∞–Ω–µ–ª–∏
            panel_height = 140
            panel_width = 400
            
            # –ß–µ—Ä–Ω—ã–π —Ñ–æ–Ω –ø–∞–Ω–µ–ª–∏
            cv2.rectangle(frame, (10, 10), (panel_width, panel_height), (0, 0, 0), -1)
            
            # –ë–µ–ª–∞—è —Ä–∞–º–∫–∞ –ø–∞–Ω–µ–ª–∏
            cv2.rectangle(frame, (10, 10), (panel_width, panel_height), (255, 255, 255), 2)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            info_lines = [
                f"FPS: {current_fps:.1f}",
                f"Frame: {self.frame_count}",
                f"Mode: {self.mode.upper()}",
                f"Humans: {humans}",
                f"Others: {non_humans}",
                f"AI Objects: {ai_detections}"
            ]
            
            # DEBUG –≤—ã–≤–æ–¥ –∫–∞–∂–¥—ã–µ 30 –∫–∞–¥—Ä–æ–≤
            if self.frame_count % 30 == 0:
                print(f"DEBUG: H={humans}, O={non_humans}, AI={ai_detections}")
            
            for i, line in enumerate(info_lines):
                y = 30 + i * 18
                
                # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                if "Humans:" in line and humans > 0:
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π
                elif "Others:" in line and non_humans > 0:
                    color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π
                elif "AI Objects:" in line and ai_detections > 0:
                    color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π
                else:
                    color = (255, 255, 255)  # –ë–µ–ª—ã–π
                
                cv2.putText(frame, line, (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # –°—Ç–∞—Ç—É—Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ –ø—Ä–∞–≤–æ–º –≤–µ—Ä—Ö–Ω–µ–º —É–≥–ª—É
            status_x = self.width - 80
            
            # AI —Å—Ç–∞—Ç—É—Å (–∑–µ–ª–µ–Ω—ã–π –∫—Ä—É–≥)
            if self.predictor:
                cv2.circle(frame, (status_x, 30), 12, (0, 255, 0), -1)
                cv2.putText(frame, "AI", (status_x - 12, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
            
            # Human detection —Å—Ç–∞—Ç—É—Å (–∂–µ–ª—Ç—ã–π –∫—Ä—É–≥)
            if self.human_detector and self.human_detector.model:
                cv2.circle(frame, (status_x, 55), 12, (0, 255, 255), -1)
                cv2.putText(frame, "HD", (status_x - 12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –ø–∞–Ω–µ–ª–∏: {e}")
        
        return frame
    
    def draw_human_detections(self, frame, detections):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–π –ª—é–¥–µ–π –Ω–∞ –∫–∞–¥—Ä–µ"""
        if not detections:
            return frame
        
        try:
            for det in detections:
                x1, y1, x2, y2 = det['bbox']
                
                if det['is_human']:
                    color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –ª—é–¥–µ–π
                    label = f"HUMAN {det['conf']:.2f}"
                else:
                    color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
                    label = f"{det['class_name'].upper()} {det['conf']:.2f}"
                
                # –†–∞–º–∫–∞
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), 
                            (x1 + label_size[0], y1), color, -1)
                
                # –¢–µ–∫—Å—Ç
                cv2.putText(frame, label, (x1, y1 - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –¥–µ—Ç–µ–∫—Ü–∏–π: {e}")
        
        return frame
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        print(f"üé¨ –ó–∞–ø—É—Å–∫ –∫–∞–º–µ—Ä—ã –≤ —Ä–µ–∂–∏–º–µ: {self.mode}")
        print("üìã –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:")
        print("   Q - –≤—ã—Ö–æ–¥")
        if self.mode == "both":
            print("   SPACE - –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ human detection")
        print()
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                break
            
            self.frame_count += 1
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫–∏
            humans = 0
            non_humans = 0
            ai_detections = 0
            
            try:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
                if self.mode == "human":
                    if self.human_detector and self.human_detector.model:
                        detections = self.human_detector.detect(frame)
                        frame = self.draw_human_detections(frame, detections)
                        
                        # –ü–æ–¥—Å—á–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–π
                        for det in detections:
                            if det['is_human']:
                                humans += 1
                            else:
                                non_humans += 1
                
                elif self.mode == "track":
                    if self.predictor:
                        try:
                            results = self.predictor.predict(frame)
                            frame = self.predictor.draw_detections(frame, results)
                            
                            # –ü–æ–¥—Å—á–µ—Ç AI –¥–µ—Ç–µ–∫—Ü–∏–π
                            if results:
                                if hasattr(results, '__len__'):
                                    ai_detections = len(results)
                                else:
                                    ai_detections = 1
                        except Exception as e:
                            print(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
                
                elif self.mode == "both":
                    # AI –¥–µ—Ç–µ–∫—Ü–∏—è
                    if self.predictor:
                        try:
                            results = self.predictor.predict(frame)
                            frame = self.predictor.draw_detections(frame, results)
                            
                            if results:
                                if hasattr(results, '__len__'):
                                    ai_detections = len(results)
                                else:
                                    ai_detections = 1
                        except Exception as e:
                            print(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
                    
                    # Human –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ –∫–ª–∞–≤–∏—à–µ
                    if self.enable_human_detection and self.human_detector and self.human_detector.model:
                        detections = self.human_detector.detect(frame)
                        frame = self.draw_human_detections(frame, detections)
                        
                        for det in detections:
                            if det['is_human']:
                                humans += 1
                            else:
                                non_humans += 1
                
                elif self.mode == "both_with_human":
                    # AI –¥–µ—Ç–µ–∫—Ü–∏—è
                    if self.predictor:
                        try:
                            results = self.predictor.predict(frame)
                            frame = self.predictor.draw_detections(frame, results)
                            
                            if results:
                                if hasattr(results, '__len__'):
                                    ai_detections = len(results)
                                else:
                                    ai_detections = 1
                        except Exception as e:
                            print(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
                    
                    # Human –¥–µ—Ç–µ–∫—Ü–∏—è –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω–∞
                    if self.human_detector and self.human_detector.model:
                        detections = self.human_detector.detect(frame)
                        frame = self.draw_human_detections(frame, detections)
                        
                        for det in detections:
                            if det['is_human']:
                                humans += 1
                            else:
                                non_humans += 1
            
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞: {e}")
            
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å
            frame = self.draw_info_panel(frame, humans, non_humans, ai_detections)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–¥—Ä
            cv2.imshow('Human Detection', frame)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord(' ') and self.mode == "both":
                self.enable_human_detection = not self.enable_human_detection
                status = "ON" if self.enable_human_detection else "OFF"
                print(f"üîÑ Human detection: {status}")
            
            # FPS –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
            if self.target_fps > 0:
                time.sleep(1.0 / self.target_fps)
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("üßπ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ö–∞–º–µ—Ä–∞ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –ª—é–¥–µ–π –∏ AI')
    parser.add_argument('mode', choices=['human', 'track', 'both', 'both_with_human'], 
                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--camera', type=int, default=0, help='ID –∫–∞–º–µ—Ä—ã')
    parser.add_argument('--weights', type=str, help='–ü—É—Ç—å –∫ –≤–µ—Å–∞–º AI –º–æ–¥–µ–ª–∏')
    parser.add_argument('--fps', type=int, default=30, help='–¶–µ–ª–µ–≤–æ–π FPS')
    parser.add_argument('--conf', type=float, default=0.25, help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏')
    
    args = parser.parse_args()
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏...")
    print(f"üìã –†–µ–∂–∏–º: {args.mode}")
    print(f"üìπ –ö–∞–º–µ—Ä–∞: {args.camera}")
    print(f"üéØ FPS: {args.fps}")
    print(f"üìä Confidence: {args.conf}")
    print()
    
    camera_handler = None
    
    try:
        camera_handler = CameraHandler(
            mode=args.mode,
            camera_id=args.camera,
            weights_path=args.weights,
            target_fps=args.fps
        )
        
        camera_handler.run()
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        if camera_handler:
            camera_handler.cleanup()


if __name__ == "__main__":
    main()